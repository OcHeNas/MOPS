# Многоуровневая организация программных систем
## Отчёт по курсовой работе
**Тема:** Разработка простого IoT-сервиса.  
**Выполнил:** Очеповский Д.Д.  
**Группа:** P4116  
**Преподаватель:** Перл И.А.  
**Дата:** 28.11.2024


### Архитектура системы
Требуется разработать IoT-сервис согласно данной архитектуре.
![Архитектура системы](https://github.com/OcHeNas/MOPS/blob/main/image.png)  
Сервис должен содержать части:
1. `Data Simulator` - сервис, эмулирующий поток данных, которые циркулируют по системе.
2. `IoT Controller` - сервис, выполняющий фильтрацию, валидацию входных данных и определяющий их дальнейшую траекторию передвижения.
3. `Rule Engine` - сервис, обрабатывающий данные от `IoT controller`. По заранее установленных правилам выполняет вставку записей в базу данных`MongoDB`.
4. `MongoDb` - хранилище данных.
5. `Compass` - визуализация данных, содержащихся в БД.
6. `Rabbitmq` - брокер сообщений для передачи данных из `IoT Controller` в `Rule Engine`.
7. `ELK stack`. Комплекс сервисов для сборки логов.

### Бизнес-логика разрабатываемого решения
1) Data simulator – компонент системы, который выполняет функцию генерирования данных для дальнейшей обработки. То есть при запуске данного компонента начинается процесс генерации данных. Сервису задаются количество устройств и суммарное кол-во запросов от них в секунду. После того, как данные сгенерированы, они сразу же отправляются через POST запрос в компонент IoT-контроллер.
2) IoT-контроллер – компонент системы, который принимает входные пакеты с данными от компонента Data simulator. Принимаемый пакет данных валидируется. После успешной валидации все одобренные сообщения отправляются в очередь брокера сообщений RabbitMQ.
Rule engine – компонент, который отвечает за обработку правил и взаимодействие с БД. Компонент ведет учет полученных из очереди пакетов, тем самым обрабатывая длящиеся и мгновенные правила.
3) RabbitMQ – с помощью брокера сообщений RabbitMQ было реализовано взаимодейтсвие двух основных компонентов: IoTcontroller и Rule engine. Данный компонент был интегрирован в систему с помощью Docker контейнера и позволил реализовать асинхронную передачу данных между нашими компонентами, а также обеспечил надежность и возможность масштабируемости. С помощью интеграции RabbitMQ была реализована гарантированная доставка данных. В нашей реализации был 1 Producer (IoT controller), очередь и 1 Consumer (Rule engine). 
4) MongoDB + Compass – данная связка позволила реализовать процесс хранения данных. С помощью MongoDB мы успешно сохраняем данные в формате JSON, который описывает структуру реализованных моделей. Через компонент Compass удобно было удобно отслеживать процесс сохранения данных в БД.
5) ELK Stack - логи формируются средствами модуля Python logging и передаются на обработку в ELK Stack при помощи filebeat. Поддерживается два уровня логов: INFO, ERROR.
6) Filebeat - инструмент для сборки логов каждого из контейнеров. В каждом из контейнеров имеется директория /var/log/... В каждой такой директории каждого контейнера создается файл .log. Директория представлена как docker volume для сохранения логов при перезапуске.
7) Logstash - хранилище для логов, собираемых filebeat.
8) Elasticsearch - поисковая система для логов, хранящихся в elasticsearch. 
Kibana GUI-сервис для визуализации данных из elasticsearch, logstash.

### Организация взаимодействия модулей
1. Каждое решение помещается в свой собственный контейнер.
2. Взаимодействие происходит при помощи `docker`-сети.
### Программное обеспечение
Помимо ранее объявленного ПО, укажем следующее:
1. `docker, docker-compose` - контейнеризация разрабатываемых решений.
2. `python, fastAPI` - основной язык программирования  
`poetry` - пакетный менеджер `Python`.
